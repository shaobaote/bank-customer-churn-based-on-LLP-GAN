{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e4973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df=pd.read_csv('D:/mac归档/研究生小论文和毕设/毕业论文/data/bank customer Churn.csv')\n",
    "    #随机打乱数据\n",
    "    np.random.seed(1)\n",
    "    df=df.sample(frac=1).reset_index(drop=True)\n",
    "    #训练结果，是否流失\n",
    "    result_var='Exited'\n",
    "    #分类型数据，需要预处理\n",
    "    cat_names=['Gender','Geography']\n",
    "    #数值型数据，可直接输入模型\n",
    "    cont_names=['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
    "    #标签\n",
    "    Y=df['Exited'].astype('int')\n",
    "    #类别变量变为独热编码，总的有4个类别变量\n",
    "    one_hot=pd.DataFrame(columns=['Female','Male','France','Germany','Spain','HasCrCard_Yes','HasCrCard_No','IsActiveMember_Yes','IsActiveMember_No'],index=[i for i in range(10000)])\n",
    "    one_hot.loc[df.Gender=='Female','Female']=1\n",
    "    one_hot.loc[df.Gender=='Male','Female']=0\n",
    "    one_hot.loc[df.Gender=='Male','Male']=1\n",
    "    one_hot.loc[df.Gender=='Female','Male']=0\n",
    "    one_hot.loc[df.Geography=='France','France']=1\n",
    "    one_hot.loc[df.Geography!='France','France']=0\n",
    "    one_hot.loc[df.Geography=='Germany','Germany']=1\n",
    "    one_hot.loc[df.Geography!='Germany','Germany']=0\n",
    "    one_hot.loc[df.Geography=='Spain','Spain']=1\n",
    "    one_hot.loc[df.Geography!='Spain','Spain']=0\n",
    "    one_hot.loc[df.HasCrCard==1,'HasCrCard_Yes']=1\n",
    "    one_hot.loc[df.HasCrCard==0,'HasCrCard_Yes']=0\n",
    "    one_hot.loc[df.HasCrCard==1,'HasCrCard_No']=0\n",
    "    one_hot.loc[df.HasCrCard==0,'HasCrCard_No']=1\n",
    "    one_hot.loc[df.IsActiveMember==1,'IsActiveMember_Yes']=1\n",
    "    one_hot.loc[df.IsActiveMember==0,'IsActiveMember_Yes']=0\n",
    "    one_hot.loc[df.IsActiveMember==1,'IsActiveMember_No']=0\n",
    "    one_hot.loc[df.IsActiveMember==0,'IsActiveMember_No']=1\n",
    "    #X为数据集，未区分训练集和测试集，用pandas提前划分；标准化处理非独热编码\n",
    "    X=pd.concat([df[cont_names],one_hot],axis=1).astype('float')\n",
    "    \n",
    "    #归一化\n",
    "    #X=X.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))#生成器最后一层是Tanh(-1,1)，把数据标准化到-1到1之间\n",
    "    \n",
    "    #标准化\n",
    "    #X=pd.concat([df[cont_names].apply(lambda x: (x - np.mean(x)) / np.std(x)),one_hot],axis=1).astype('float')\n",
    "    \n",
    "    #print(X.loc[10,:])\n",
    "    #print(Y.loc[10])\n",
    "    return X,Y\n",
    "    #X_.reset_index(drop=True, inplace=True);Y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "########k折划分############        \n",
    "def get_k_fold_data(k, i, X, y):  ###此过程主要是步骤（1）\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据，分开放，X_train为训练数据，X_valid为验证数据   \n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k  # 每份的个数:数据总条数/折数（组数）\n",
    "    X_train, Y_train = pd.DataFrame(), pd.Series()#要用series\n",
    "    for j in range(k):\n",
    "        ##idx 为每组 valid\n",
    "        X_part = X.iloc[j * fold_size: (j + 1) * fold_size,:]\n",
    "        \n",
    "        Y_part=y[j * fold_size: (j + 1) * fold_size]\n",
    "        if j == i: ###第i折作valid\n",
    "            X_test, Y_test = X_part, Y_part\n",
    "        #elif X_train is None:\n",
    "            #X_train, Y_train = X_part, Y_part\n",
    "        else:\n",
    "            X_train = pd.concat([X_train, X_part], axis=0) #dim=0增加行数，竖着连接\n",
    "            Y_train = pd.concat([Y_train, Y_part], axis=0)\n",
    "    \n",
    "\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "    Y_train.reset_index(drop=True, inplace=True)\n",
    "    Y_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return X_train,Y_train, X_test, Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "134f4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,f1_score,accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f28b597b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1折交叉验证\n",
      "\n",
      "第2折交叉验证\n",
      "\n",
      "第3折交叉验证\n",
      "\n",
      "第4折交叉验证\n",
      "\n",
      "第5折交叉验证\n",
      "\n",
      "5折交叉验证各指标均值和标准差:\n",
      "\n",
      "0.7898 0.007004284403135005 0.10251708265399309 0.028164204259429084 0.6753882430687235 0.012732685076069956\n",
      "第1折交叉验证\n",
      "\n",
      "第2折交叉验证\n",
      "\n",
      "第3折交叉验证\n",
      "\n",
      "第4折交叉验证\n",
      "\n",
      "第5折交叉验证\n",
      "\n",
      "5折交叉验证各指标均值和标准差:\n",
      "\n",
      "0.8618 0.006830812543175256 0.5751992646023332 0.009999683533090109 0.8465728922800462 0.009578194160663786\n",
      "第1折交叉验证\n",
      "\n",
      "第2折交叉验证\n",
      "\n",
      "第3折交叉验证\n",
      "\n",
      "第4折交叉验证\n",
      "\n",
      "第5折交叉验证\n",
      "\n",
      "5折交叉验证各指标均值和标准差:\n",
      "\n",
      "0.8619999999999999 0.004764451699828626 0.5784523136276819 0.021722837736857573 0.8652505263799621 0.010868746650681715\n"
     ]
    }
   ],
   "source": [
    "def train_start(model):\n",
    "    k=5#K折交叉验证\n",
    "    X,Y=load_data()\n",
    "    precision,recall,F1,acc,AUC=[],[],[],[],[]\n",
    "    for i in range(k):\n",
    "        print('第{}折交叉验证\\n'.format(i+1))\n",
    "        X_train,Y_train, X_test, Y_test = get_k_fold_data(k, i, X, Y) \n",
    "        fit=model.fit(X_train,Y_train)\n",
    "        fit_prediction_train =fit.predict(X_train)\n",
    "        fit_prediction_test = fit.predict(X_test)\n",
    "        ACC=accuracy_score(fit_prediction_test, Y_test)\n",
    "        f1=f1_score(fit_prediction_test, Y_test)\n",
    "        auc=roc_auc_score(Y_test, fit.predict_proba(X_test)[::,1])\n",
    "        acc.append(ACC);F1.append(f1);AUC.append(auc)\n",
    "    print('5折交叉验证各指标均值和标准差:\\n')\n",
    "    print(np.mean(acc),np.std(acc),np.mean(F1),np.std(F1),np.mean(AUC),np.std(AUC))\n",
    "    \n",
    "\n",
    "LR= LogisticRegression(solver='liblinear')\n",
    "train_start(LR)\n",
    "\n",
    "RF=RandomForestClassifier(n_estimators=100)\n",
    "train_start(RF)\n",
    "\n",
    "GB=GradientBoostingClassifier(n_estimators=100)\n",
    "train_start(GB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d78ccea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1折交叉验证\n",
      "\n",
      "[11:32:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "第2折交叉验证\n",
      "\n",
      "[11:32:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "第3折交叉验证\n",
      "\n",
      "[11:32:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "第4折交叉验证\n",
      "\n",
      "[11:32:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "第5折交叉验证\n",
      "\n",
      "[11:32:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "5折交叉验证各指标均值和标准差:\n",
      "\n",
      "0.8554 0.004386342439892282 0.5808734270977476 0.023435993601733294 0.8500664754523173 0.01011822045659159\n"
     ]
    }
   ],
   "source": [
    "XGB=XGBClassifier()\n",
    "train_start(XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38dd58b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1折交叉验证\n",
      "\n",
      "第2折交叉验证\n",
      "\n",
      "第3折交叉验证\n",
      "\n",
      "第4折交叉验证\n",
      "\n",
      "第5折交叉验证\n",
      "\n",
      "5折交叉验证各指标均值和标准差:\n",
      "\n",
      "0.7963 0.006454455825241968 0.0 0.0 0.5 0.0\n"
     ]
    }
   ],
   "source": [
    "SVM= SVC(gamma='auto')\n",
    "train_start(SVM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
